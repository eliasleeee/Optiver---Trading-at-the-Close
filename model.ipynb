{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2023-12-18T23:13:20.212466Z","iopub.execute_input":"2023-12-18T23:13:20.212884Z","iopub.status.idle":"2023-12-18T23:13:24.073364Z","shell.execute_reply.started":"2023-12-18T23:13:20.212853Z","shell.execute_reply":"2023-12-18T23:13:24.072215Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-18T23:13:35.178026Z","iopub.execute_input":"2023-12-18T23:13:35.179215Z","iopub.status.idle":"2023-12-18T23:13:35.188025Z","shell.execute_reply.started":"2023-12-18T23:13:35.179166Z","shell.execute_reply":"2023-12-18T23:13:35.186942Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"import os, io\n# os.environ['CUDA_VISIBLE_DEVICES']='2,3,'\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n\nimport copy\nimport statsmodels\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom pathlib import Path\nimport warnings\nfrom matplotlib import pyplot as plt\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nimport torch\n\nfrom pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\nfrom pytorch_forecasting.data import GroupNormalizer\nfrom pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss, MAE\nfrom pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\nfrom pytorch_forecasting.data.encoders import NaNLabelEncoder\nimport pytorch_forecasting\nfrom tqdm import tqdm\nimport multiprocessing as mp","metadata":{"execution":{"iopub.status.busy":"2023-12-18T22:39:19.820916Z","iopub.execute_input":"2023-12-18T22:39:19.822493Z","iopub.status.idle":"2023-12-18T22:39:20.210588Z","shell.execute_reply.started":"2023-12-18T22:39:19.822444Z","shell.execute_reply":"2023-12-18T22:39:20.208886Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, LearningRateMonitor, ModelCheckpoint\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorBoardLogger\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/__init__.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m _PACKAGE_ROOT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[1;32m     18\u001b[0m _PROJECT_ROOT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(_PACKAGE_ROOT)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/__init__.py:14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_stats_monitor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceStatsMonitor\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mearly_stopping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/base.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STEP_OUTPUT\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCallback\u001b[39;00m(abc\u001b[38;5;241m.\u001b[39mABC):\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Abstract base class used to build new callbacks.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Subclass this class and override any of the relevant hooks\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/__init__.py:18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"General utilities.\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m move_data_to_device  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AllGatherGrad, rank_zero_info, rank_zero_only  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     AMPType,\n\u001b[1;32m     22\u001b[0m     DeviceType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     ModelSummaryMode,\n\u001b[1;32m     27\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/apply_func.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _compare_version, _TORCHTEXT_AVAILABLE\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TORCHTEXT_AVAILABLE:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_compare_version\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.9.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Batch\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/imports.py:54\u001b[0m, in \u001b[0;36m_compare_version\u001b[0;34m(package, op, version, use_base_version)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compare package version with some requirements.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m>>> _compare_version(\"torch\", operator.ge, \"0.1\")\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mTrue\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     pkg \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, DistributionNotFound):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_torch_home\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      8\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/_extension.py:64\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_ops.py:573\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    568\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n","File \u001b[0;32m/opt/conda/lib/python3.10/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n","\u001b[0;31mOSError\u001b[0m: /opt/conda/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN2at4_ops10select_int4callERKNS_6TensorElN3c106SymIntE"],"ename":"OSError","evalue":"/opt/conda/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN2at4_ops10select_int4callERKNS_6TensorElN3c106SymIntE","output_type":"error"}]},{"cell_type":"code","source":"\n\ndef categorize_columns(df, threshold=1):\n    \"\"\"\n    Categorize columns of a dataframe into continuous and categorical based on a threshold\n    for the number of unique values.\n\n    Parameters:\n    df: The dataframe to categorize columns from.\n    threshold: The threshold for determining categorical columns based on\n                     the unique number of values.\n\n    Returns:\n    continuous_cols: List of names of continuous columns.\n    categorical_cols: List of names of categorical columns.\n    \"\"\"\n    exclude_cols = ['time_idx', 'target', 'stock_id', 'date_id']\n    continuous_cols = []\n    categorical_cols = []\n\n    for col in df.columns:\n        if col in exclude_cols:\n            continue\n        if pd.api.types.is_numeric_dtype(df[col]):\n            if len(df[col].unique()) > threshold:\n                continuous_cols.append(col)\n            else:\n                categorical_cols.append(col)\n        elif pd.api.types.is_categorical_dtype(df[col]):\n            categorical_cols.append(col)\n\n    return continuous_cols, categorical_cols\n\n\ndef load_csv(file_ids,idx):\n    print(idx)\n    print(file_ids)\n    df = []\n    for i in tqdm(file_ids):\n        df.append(pd.read_csv(f'data/v12/train_intraday_{i}-{i+9}.csv'))\n    return {idx: pd.concat(df, ignore_index=True)}\n\n\nresults = []\nprint(\"Loading data\")\nfor i in tqdm(range(0,480,10)):\n    results.append(pd.read_csv(f'data/v12/train_intraday_{i}-{i+9}.csv'))\n\n# num_cores = 10\n# pool = mp.Pool(num_cores)\n# file_ids = list(range(0,480,10))\n\n# steps=5\n# pool_res=[]\n# for i in range(0,len(file_ids),steps):\n#     pool_res.append(pool.apply_async(load_csv, args=(file_ids[i:i+steps],i)))\n\n# pool.close()\n# pool.join()\n# for res in pool_res:\n#     results.append(res.get())\n\nresults.append(pd.read_csv(f'data/v12/train_intraday_480-480.csv'))\ndf = pd.concat(results, ignore_index=True)\ndf['time_idx'] = range(len(df))\ndf.fillna(1, inplace=True)\n#df = df.drop([\"Unnamed: 0\"], axis=1)\ncontinuous_cols, categorical_cols = categorize_columns(df)\ncontinuous_cols = continuous_cols[1:] # remove the index col\nlen(continuous_cols)\n\nmax_prediction_length = 1\nmax_encoder_length = 55\ntraining_cutoff = int(df[\"time_idx\"].max() * 0.8)\n\ntraining = TimeSeriesDataSet(\n        df[lambda x: x.time_idx <= training_cutoff],\n        time_idx=\"time_id\",\n        target=\"target\",\n        group_ids=[\"stock_id\"],\n        min_encoder_length=max_encoder_length // 2,\n        max_encoder_length=max_encoder_length,\n        min_prediction_length=1,\n        max_prediction_length=max_prediction_length,\n        static_reals=[],\n        time_varying_known_categoricals=[],\n        time_varying_known_reals=['date_id'],\n        time_varying_unknown_categoricals=categorical_cols,\n        time_varying_unknown_reals=continuous_cols,\n        categorical_encoders={\n            'stock_id':pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n            'seconds_in_bucket':pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n            'imbalance_buy_sell_flag':pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n        },\n        target_normalizer=GroupNormalizer(\n            groups=[\"stock_id\"],\n        ),\n        add_relative_time_idx=True,\n        add_target_scales=True,\n        add_encoder_length=True,\n        allow_missing_timesteps=True,\n        #add_nan=True,\n        )\n\n# min_prediction_idx=training.index.time.max() + 1,\nvalidation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\nbatch_size = 128\ntrain_dataloader = training.to_dataloader(\n    train=True,\n    batch_size=batch_size,\n    num_workers=8,\n    pin_memory=True,\n)\nval_dataloader = validation.to_dataloader(\n    train=False,\n    batch_size=batch_size,\n    num_workers=8,\n    pin_memory=True,\n)\nprint(training.get_parameters())\n\npl.seed_everything(42)\nearly_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-5, patience=10, verbose=False, mode=\"min\")\nlr_logger = LearningRateMonitor()  # log the learning rate\nlogger = TensorBoardLogger(\"lightning_logs/v12\")  # logging results to a tensorboard\n\ncheckpoint_callback = ModelCheckpoint(\n    dirpath='lightning_logs/v12/checkpoints',\n    filename='{epoch}-{val_loss:.2f}',\n    save_top_k=5,\n    verbose=True,\n    monitor='val_loss',\n    mode='min',\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrainer = pl.Trainer(\n    max_epochs=20,\n    gpus=list(range(torch.cuda.device_count())),\n    gradient_clip_val=0.1,\n    limit_train_batches=10000,\n    callbacks=[lr_logger,checkpoint_callback], #early_stop_callback],\n    logger=logger,\n    accelerator=\"ddp\",\n)\n\ntft = TemporalFusionTransformer.from_dataset(\n    training,\n    learning_rate=5e-4,\n    hidden_size=32,\n    attention_head_size=8,\n    dropout=0.3,\n    hidden_continuous_size=128,\n    output_size=1,\n    loss=MAE(),\n    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n    reduce_on_plateau_patience=4,\n)\nprint(f\"Number of parameters in network: {tft.size() / 1e3:.1f}k\")\ntft = tft.to('cuda')\n\ntrainer.fit(\n    tft,\n    train_dataloaders=train_dataloader,\n    val_dataloaders=val_dataloader,\n)\n\ntrainer.save_checkpoint(\"last_v12.ckpt\")","metadata":{},"execution_count":null,"outputs":[]}]}